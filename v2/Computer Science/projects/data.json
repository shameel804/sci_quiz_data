[
    {
        "title": "Arrays vs Linked Lists ðŸ“‹",
        "ques": "Compare **arrays** and **linked lists** with their time complexities.",
        "answer": {
            "type": "text",
            "content": "| Operation | Array | Linked List |\n|-----------|-------|-------------|\n| Access by index | **O(1)** | O(n) |\n| Search | O(n) | O(n) |\n| Insert at beginning | O(n) | **O(1)** |\n| Insert at end | O(1)* | O(n)/O(1)** |\n| Delete | O(n) | O(1) if have node |\n\n*If array has space; **If tail pointer kept\n\n**Array:** Contiguous memory, fixed size\n**Linked List:** Nodes with pointers, dynamic size"
        },
        "explanation": "Arrays have better cache locality. Linked lists are better when many insertions/deletions at arbitrary positions."
    },
    {
        "title": "Stacks and Queues ðŸ“š",
        "ques": "Explain **stacks** and **queues** with real-world examples.",
        "answer": {
            "type": "text",
            "content": "**Stack (LIFO):**\n- Last In, First Out\n- Operations: push, pop, peek\n- All O(1)\n\n**Examples:**\n- Browser back button\n- Undo/Redo\n- Function call stack\n- Expression evaluation\n\n**Queue (FIFO):**\n- First In, First Out\n- Operations: enqueue, dequeue\n- All O(1)\n\n**Examples:**\n- Print queue\n- Customer service line\n- BFS traversal"
        },
        "explanation": "Implement stack with array or linked list. Implement queue with circular array or linked list."
    },
    {
        "title": "Binary Trees ðŸŒ³",
        "ques": "What is a **binary search tree**? Show the three traversal orders.",
        "answer": {
            "type": "text",
            "content": "**Binary Search Tree (BST):**\n- Each node has at most 2 children\n- Left subtree < node < right subtree\n- Operations: O(log n) average, O(n) worst\n\n**Traversals:**\n```\n        4\n       / \\\n      2   6\n     / \\\n    1   3\n```\n\n| Order | Result | Use |\n|-------|--------|-----|\n| **In-order** (L-Root-R) | 1,2,3,4,6 | Sorted order |\n| **Pre-order** (Root-L-R) | 4,2,1,3,6 | Copy tree |\n| **Post-order** (L-R-Root) | 1,3,2,6,4 | Delete tree |"
        },
        "explanation": "Balanced BSTs (AVL, Red-Black) ensure O(log n) worst case. Self-balancing on insertion/deletion."
    },
    {
        "title": "Heaps ðŸ”ï¸",
        "ques": "Explain **heaps** and their use in priority queues.",
        "answer": {
            "type": "text",
            "content": "**Heap Properties:**\n- Complete binary tree\n- **Max-heap:** Parent â‰¥ children\n- **Min-heap:** Parent â‰¤ children\n\n**Operations:**\n| Operation | Time |\n|-----------|------|\n| Insert | O(log n) |\n| Extract max/min | O(log n) |\n| Peek | O(1) |\n| Build heap | O(n) |\n\n**Priority Queue Uses:**\n- Dijkstra's algorithm\n- Event scheduling\n- Huffman coding\n- Heap sort"
        },
        "explanation": "Heaps typically stored as arrays. Parent at i, children at 2i+1 and 2i+2."
    },
    {
        "title": "Hash Maps ðŸ—ºï¸",
        "ques": "How do **hash maps** achieve O(1) average lookup?",
        "answer": {
            "type": "text",
            "content": "**Hash Map Structure:**\nArray of buckets + hash function\n\n**Process:**\n1. key â†’ hash(key) â†’ index\n2. Store (key, value) at index\n3. Retrieval: same hash â†’ same index\n\n**Collision Handling:**\n- **Chaining:** Linked list at each bucket\n- **Open addressing:** Linear/quadratic probing\n\n**Good Hash Function:**\n- Deterministic\n- Uniform distribution\n- Fast to compute"
        },
        "explanation": "Load factor = n/buckets. Resize when load factor exceeds threshold (~0.75)."
    },
    {
        "title": "Graphs ðŸ•¸ï¸",
        "ques": "Compare **adjacency matrix** vs **adjacency list** representations.",
        "answer": {
            "type": "text",
            "content": "**Graph: V vertices, E edges**\n\n| Aspect | Adjacency Matrix | Adjacency List |\n|--------|-----------------|----------------|\n| Space | O(VÂ²) | O(V + E) |\n| Edge lookup | O(1) | O(degree) |\n| Add edge | O(1) | O(1) |\n| Iterate neighbors | O(V) | O(degree) |\n| Best for | Dense graphs | Sparse graphs |\n\n**Most real graphs are sparse â†’ use adjacency list**"
        },
        "explanation": "Social networks, web graphs are sparse. Complete graphs (dense) rare in practice."
    },
    {
        "title": "Tries ðŸ”¤",
        "ques": "What is a **trie** and what is it used for?",
        "answer": {
            "type": "text",
            "content": "**Trie (Prefix Tree):**\nTree for storing strings, sharing common prefixes\n\n**Example:** Storing [\"cat\", \"car\", \"card\"]\n```\n     root\n       |\n       c\n       |\n       a\n      / \\\n     t   r\n         |\n         d\n```\n\n**Operations:** O(m) where m = string length\n\n**Uses:**\n- Autocomplete\n- Spell checkers\n- IP routing tables\n- Word games (Scrabble)"
        },
        "explanation": "Space efficient for many strings with shared prefixes. Compressed tries (radix trees) save more space."
    },
    {
        "title": "Balanced Trees âš–ï¸",
        "ques": "Why are **balanced trees** (AVL, Red-Black) important?",
        "answer": {
            "type": "text",
            "content": "**Problem with Unbalanced BST:**\nInserting sorted data: 1,2,3,4,5 creates a linked list!\nâ†’ Operations become O(n)\n\n**Self-Balancing Trees:**\n| Tree | Balance Condition |\n|------|------------------|\n| **AVL** | Height difference â‰¤ 1 |\n| **Red-Black** | # black nodes equal on all paths |\n| **B-Tree** | Degree constraints |\n\n**Result:** Guaranteed O(log n) operations\n\n**AVL:** Stricter balance, faster lookup\n**Red-Black:** Faster insert/delete"
        },
        "explanation": "Red-Black trees used in most language standard libraries. B-Trees used in databases/filesystems."
    },
    {
        "title": "Union-Find ðŸ”—",
        "ques": "Explain the **Union-Find** (Disjoint Set) data structure.",
        "answer": {
            "type": "text",
            "content": "**Union-Find:**\nTrack elements partitioned into disjoint sets\n\n**Operations:**\n- **Find(x):** Which set contains x?\n- **Union(x, y):** Merge sets containing x and y\n\n**Optimizations:**\n| Technique | Effect |\n|-----------|--------|\n| **Path compression** | Find points directly to root |\n| **Union by rank** | Attach smaller tree to larger |\n\n**With both:** Nearly O(1) amortized\n\n**Uses:**\n- Kruskal's MST algorithm\n- Connected components\n- Cycle detection"
        },
        "explanation": "Ackermann inverse function Î±(n) â‰¤ 5 for all practical n. Effectively constant time."
    },
    {
        "title": "Segment Trees ðŸ“Š",
        "ques": "What is a **segment tree** and when is it used?",
        "answer": {
            "type": "text",
            "content": "**Segment Tree:**\nTree for range queries and updates\n\n**Building:** O(n)\n**Query/Update:** O(log n)\n**Space:** O(n)\n\n**Example Uses:**\n- Range sum queries\n- Range minimum/maximum\n- With lazy propagation: range updates\n\n**Structure:**\n- Leaf nodes: individual elements\n- Internal nodes: aggregate of children\n- Root: aggregate of entire array"
        },
        "explanation": "Fenwick tree (BIT) is simpler alternative for cumulative queries. Segment trees more flexible."
    }
]